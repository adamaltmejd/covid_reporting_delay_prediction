% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode
% !BIB TS-program = biber
% !TeX root = ./paper.tex
\documentclass[a4paper,11pt,article,oneside,openany,american]{memoir}
\usepackage[memoir,bibliography]{setupscript}
\addbibresource{bibliography.bib}

% Customization
\usepackage{array}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{amsthm}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}
\newcommand{\mv}[1]{{\boldsymbol{#1}}}

% TITLE

\title{Nowcasting Covid-19 statistics reported with delay: a case-study of Sweden}
\date{\today}
\author{
	Adam Altmejd\thanks{SOFI, Stockholm University and Swedish House of Finance, \href{mailto:adam@altmejd.se}{adam@altmejd.se}} \and
	Joacim Rocklöv\thanks{Department of Public Health and Clinical Medicine, Umeå University,\href{mailto:joacim.rocklov@umu.se}{joacim.rocklov@umu.se }}\thanks{Heidelberg Institute of Global Health, University of Heidelberg}  \and
	Jonas Wallin\thanks{Department of statistics, Lund university, \href{mailto:jonas.wallin81@gmail.com}{jonas.wallin81@gmail.com}}
}

\begin{document}
\frontmatter%
\begin{titlingpage}
    \maketitle
    \begin{abstract}
        The new corona virus disease --- COVID-2019 --- is rapidly spreading through the world. The availability of unbiased timely statistics of trends in disease events are a key to effective responses. But due to reporting delays, the most recently reported numbers are frequently underestimating of the total number of infections, hospitalizations and deaths creating an illusion of a downward trend. Here we describe a statistical methodology for predicting true daily quantities and their uncertainty, estimated using historical reporting delays. The methodology takes into account the observed distribution pattern of the lag. It is derived from the ``removal method'', a well-established estimation framework in the field of ecology.
	\end{abstract}

	%\noindent Keywords:

\end{titlingpage}
%\tableofcontents*
%%%%%%%%%%%%%%%%%%%
% MAIN TEXT SECTION
\mainmatter%

\chapter{Pandemic response demands timely data}
The new corona virus pandemic is affecting societies all around the world. As countries are challenged to control and fight back, they are in need of timely, unbiased, data for monitoring trends and making fast and well-informed decisions (\cite{No_author_2020_coronavirus_three}). Official statistics are usually reported with long delay after thorough verification, but in the midst of a deadly pandemic, real time data is of critical importance for policymakers (\cite{Jajosky2004_evaluation_reporting}). The latest data are often not finalized, but change as new information is reported. In fact, reporting delays make the most recent days have the least cases accounted for, producing a dangerous illusion of an always improving outlook.

Still, these unfinished statistics offer crucial information. If the pandemic is indeed slowing, we should not wait for the data to be finalized before using it. Rather, we argue that actual case counts and deaths should be nowcasted to account for reporting delay, thus allowing policymakers to use the latest numbers availiable without beinig misled by reporting bias.

Such predictions provide an additional feature that is perhaps even more important. They explicitly model the uncertainty about these unknown quantities, ensuring that all users of these data have the same view of the current state of the epidemic.

In this paper we describe a statistical methodology for nowcasting the epidemic statistics, such as hospitalizations or deaths, and their degrees of uncertainty, based on the daily reported event frequency and the observed distribution pattern of reporting delays. The prediction model is building on methods developed in ecology, referred to as the ``removal method'' (\cite{Pollock1991_review_papers}).

To help motivate why such forecasting is needed, we now turn to the case of Sweden. The model is flexible by design, however, and could easily be applied to other countries as well.

\section{The current situation of COVID-19 in Sweden}
The Swedish Public Health Agency updates the COVID-19 statistics daily\footnote{The data is published on \url{https://www.folkhalsomyndigheten.se/smittskydd-beredskap/utbrott/aktuella-utbrott/covid-19/bekraftade-fall-i-sverige/}.}. During a press conference, they present updates on the number of deaths, admissions to hosiptals and intensive care, as well as case counts.

One of the reasons for following these indicators is to enable public health professionals and the public to observe the evolving patterns of the epidemic (\cite{Anderson2020_how_will}). In relation to policy, it is of specific interest to understand if the growth rates changes, which could indicate the need for a policy response. However, in each daily report only a proportion of the number of recent deaths is yet known, and this bias produces the illusion of a downward trend.

The death counts suffer from the longest reporting delay. In their daily press conference, the Swedish Public Health Agency warns for this by stopping the reported 7-day moving average trend line 10 days before the latest date. But not only are deaths often reported far further back than 10 days, a bar plot still shows the latest information, creating a sense of a downward trend. In fact, this might be the reason why the number of daily deaths have been underestimated repeatedly. At the peak, deaths were initially believed to level out at around 60 per day, but after all cases had been reported more than two weeks later, the actual number was close to 120 (\cite{Ohman2020_antalet_virusdoda}).

\chapter{The removal method}
We propose to use the removal method, developed in animal management (\cite{Pollock1991_review_papers}), to present an estimate of the actual frequencies at a given day and their uncertainty. The method has a long history dating back at least to the 1930s (\cite{Leslie1939_attempt_determine}). However, the first refined mathematical treatment of the method is credited to \cite{Moran1951_mathematical_theory}, more modern derivatives exits today (\cite{Matechou2016_open_models}). It is a commonly applied method today when analyzing age cohorts in fishery and wildlife management.

The removal method that has three major advantages over simply reporting moving averages:

\begin{itemize}
	\item it does not relay any previous trend in the data,
	\item we can generate prediction intervals for the uncertainty about daily true frequencies,
	\item the uncertainty estimates can be carried over to epidemiological models to help create more realistic models.
\end{itemize}

A classic example where the method proposed to solve this problem has been used is in estimating statistics of trapping a closed population of animals (\cite{Pollock1991_review_papers}). Each day the trapped animals are collected, and kept, and if there is no immigration the number of trapped animals the following days will, on average, decline. This pattern of declining number of trapped animals allows one to draw inference of the underlying population size. Here we replace the animal population with the true number of deaths
on a given day. Instead of traps we have the new reports of COVID--19 events. As the number of new reported deaths for a given day declines, we can draw inference on how many actually died that day. If we assume that the reporting structure is constant over time we can after a while quickly get good estimate of the actual number.

Suppose for example that on day one, 4 individuals are reported dead for that day. On the second day, 10 deaths are recorded for day two. Then, with no further information, it is reasonable to assume that more people died on day two. If the proportion reported on the first day is 3\%, the actual number of deaths would be 133 for day one and 333 for day two.

If additionally, 60 deaths are reported during the second day to have happened during day one, and on the third day, only 40 are reported for day two, we now have conflicting information. From the first-day reports it seemed like more people had died during day two, but the second day-reports gave the opposite indication. The model we propose systematically deals with such data, and handles many other sources of systematic variation in reporting delay. In fact, the Swedish reporting lag follows a calendar pattern. The number of events reported during weekends is much smaller. To account for this, we allow the estimated proportions of daily reported cases to follow a probability distribution taking into consideration what type of day it is.

\chapter{Applying the model to COVID-19 in Sweden}
We propose a Bayesian version of the removal model that assumes an overdispersed binomial distribution for the daily observations of deaths in Sweden in COVID-19. We then calculate the posterior distribution, prediction median and 95\% prediction intervals of the expected deaths from the reported deaths on each specific day. The method and algorithm is thoroughly described in the Supplementary Information.

To get accurate estimates we apply two institution-specific corrections. First, we only count workdays as constituting reporting delay, as very few deaths are reported during weekends. Second, we apply a constant bias correction to account for the fact that Swedish deaths come from two distinct populations with different trends: deaths in hospitals, and in elderly care.

In Figure~\ref{fig:latest_prediction} we apply the model to the latest statistics from Sweden. The graph shows reported and predicted deaths (with uncertainty intervals) as bars, and a dashed line plots the 7-day (centered) moving average. A version without predictions is used in the Public Health Agency´s daily press briefings. As expected, the model provides estimates of actual deaths considerably above the reported number of deaths. Not how the model predicts additional deaths above the moving average line.

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{../plots/latest_prediction}
    \caption{Swedish Covid-19 deaths as of 2020-06-04 and model predictions}
    \label{fig:latest_prediction}
\end{figure}

\section{Model Performance}
To say judge whether or not the model is accurate we need to compare it to a benchmark. The moving average of reported deaths is not useful, since it becomes strongly biased for deaths that occurred within the last week. Instead, we create a benchmark prediction by a Normal distribution where the mean and standard deviation is taken from the historical lags from the last two weeks to the reported numbers\footnote{For a death date two days ago we add the mean of deaths reported after 3 days, 4 days, etc. We use the sum of standard deviations to generate the prediction intervals, assuming that lags are independent across days. The exact calculation is described in the appendix.}. 

Figure~\ref{fig:four_dates} depicts four randomly chosen dates where the model is compared to the benchmark. The model and the benchmark are tasked with predicting the total number of individuals who have died at a given date and have been reported within 14 days of that date. As time progresses, more deaths are reported and the dashed grey line approaches the horizontal line. Meanwhile model uncertainty decreases.

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{../plots/lag_prediction_by_date}
    \caption{Model accuracy over time for four dates, compared to benchmark}
    \label{fig:four_dates}
\end{figure}

Figure~\ref{fig:model_metrics} shows model performance compared to the benchmark for three difference performance metrics. All three graphs are based on predictions of reported deaths within 14 days, and show how performance increases as more data has been reported. Each data point is the average of all dates where predictions can be evaluated. SCRPS is a measure of accuracy that rewards precision, it is a proper scoring rule like the continuous probability rank score or the Brier score (see definition in Appendix) \cite{bolin2019scale}. The central plot shows the width of the prediction intervals, and the rightmost one the proportion of PI´s that cover the true value.

Benchmark and model point estimates are similarly close to the truth. The model produces tighter prediction intervals however, they are too tight between day 8-5 lags to reporting, see Figure \ref{fig:model_metrics}, this is likely due to that Swedish Public Health Agency does a database search during only certain days to match people reported dead to Covid infected. This type of reporting is currently not implemented in the model hence the poorer performance during these lags. 

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{../plots/model_metrics}
    \caption{Model accuracy over time for four dates, compared to a benchmark}
    \label{fig:model_metrics}
\end{figure}

\chapter{Implications and limitations}
The model proposed here can estimate the trends in surveillance data with reporting delays, such as the daily COVID-19 reports in Sweden. To generate accurate estimates of the actual event frequencies based on these reports is highly relevant and can have large implications for interpretations of the trends and evolution of disease outbreaks. In Sweden, delays are considerable and exhibit a weekday and holiday pattern that need to be accounted for to draw conclusions from the data. The method and algorithm proposed overcomes major shortcomings in the daily interpretation and practice analyzing and controlling the novel Corona virus pandemic. It also provides valuable measures of uncertainty around these estimates, showing users how large the range of possible outcomes can be.

Whenever case statistics are collected from multiple sources and attributed to its actual event date in the middle of a public health emergency, similar reporting delays to the ones in Sweden will necessarily occur. The method described thus has implications and value beyond Sweden, for any situation where nowcasts of disease event frequencies are of relevance to public health.

Nevertheless, the method also has its limitations. As presented, the model assumes that all deaths are reported in the same manner. Given there exists many regions in Sweden this is unlikely to be the case. For example, it is easy to see that the Swedish region Västra Götland follows a different reporting structure than Stockholm. Building a model for each region separately would most likely give better results and make the assumptions more reasonable. Unfortunately we do not currently have access to the high resolution data required to do so. 



Moreover, deaths are reported from two distinct populations that seem to follow different trends. At the time of writing, the daily deaths in elderly care, reported with a longer delay, seem to be decreasing slower than hospital deaths. But statistics offer only aggregate numbers, prohibiting us from modeling two distinct processes. However, we have noted a clear decline in proportions of deaths reported the two first working days. For example the number of deaths occurring at the second of April $\approx 30\%$ of deaths where reported within the first two working days whereas for the eighteens of May only $\approx 10\%$ where reported during the two first working days. We address this by assuming that the deaths reported during the two first working days comes from a different population then the remainder of days.

Another limitation is that the model assumes that the number of new reported deaths for a given day cannot be negative, which is not actually true, due to miscount or misclassification of days. The number of such cases is very small, however, and its removal should not make much difference. The central assumption of the model is that the proportions deaths reported each day is fixed (up to the known covariates). If actual reporting standards change over time, the model will not be able to account for this. But reporting likely becomes faster as the crisis infrastructure improves. One can imagine that after a while the reporting improves, or is changed, if this is not accounted for by a covariate in the model, it will report incorrect numbers. Of course, there might be unknown variables that we have failed to incorporate, but at the least the model is an improvement from the estimates using moving averages. When the covariates to the reporting delay pattern are known, the model can incorporate them and provide more accurate predictions. 

\chapter{Conclusion}
In this paper, we provide a method to accurately nowcast daily Covid-19 statistics that are reported with delay. By systematically modelling the delay, policy makers can avoid dangerous illusory downward trends. Our model also gives precise uncertainty intervals, making sure users of these statistics are aware of the fast-paced changes that are possible during this pandemic.

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
\printbibliography%
\backmatter%
\appendix%
\chapter{Appendix}
\input{appendix.tex}%

\end{document}

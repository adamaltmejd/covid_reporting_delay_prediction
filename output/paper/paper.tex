% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode
% !BIB TS-program = biber
% !TeX root = ./paper.tex
\documentclass[a4paper,11pt,article,oneside,openany,american]{memoir}
\usepackage[memoir,bibliography]{setupscript}
\addbibresource{bibliography.bib}

% Customization
\usepackage{array}
\usepackage{multirow}
\usepackage{tabularx}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}

% TITLE

\title{Nowcasting Covid-19 statistics reported with delay: a case-study of Sweden}
\date{\today}
\author{
	Adam Altmejd\thanks{SOFI, Stockholm University and Swedish House of Finance, \href{mailto:adam@altmejd.se}{adam@altmejd.se}} \and
	Joacim Rocklöv \and
	Jonas Wallin
}

\begin{document}
\frontmatter%
\begin{titlingpage}
    \maketitle
    \begin{abstract}
        The new corona virus disease - COVID-2019- is rapidly spreading through the world. The availability of unbiased timely statistics of trends in disease events are a key to effective responses. But due to reporting delays, the most recently reported numbers are frequently underestimating of the total number of infections, hospitalizations and deaths creating an illusion of a downward trend. Here we describe a statistical methodology for predicting the actual daily number occurring events a specific day, and its uncertainty, based on the daily reported event frequency. The methodology takes into account the observed distribution pattern of the delay and can be derived from the “removal method”, a well-established method in the field of ecology.
	\end{abstract}

	\noindent Keywords:

\end{titlingpage}
%\tableofcontents*
%%%%%%%%%%%%%%%%%%%
% MAIN TEXT SECTION
\mainmatter%

\chapter{Pandemic response demands timely data}
The new corona virus pandemic is affecting societies all around the world. As countries are challenged to control and fight back, they are in need of timely, unbiased, data for monitoring trends and making fast and well-informed decisions (\cite{No_author_2020_coronavirus_three}). Official statistics are usually reported with long delay after thorough verification, but in the midst of a deadly pandemic, real time data is of critical importance for policymakers (\cite{Jajosky2004_evaluation_reporting}). The latest data are often not finalized, but change as new statistics are reported. In fact, since these updates are usually in the form of delayed reporting. Since the most recent days then have the least cases, such systematic underreporting gives the dangerous picture of an always improving situation.

Still, these unfinished statistics offer crucial information. If the pandemic is indeed slowing, we should not wait for the data to be finalized before using it. Rather, we argue that actual case counts and deaths should be nowcasted to account for any reporting delay and ensure policymakers are using the most accurate numbers available.

Such predictions provide an additional feature that is perhaps even more important. They explicitly model the uncertainty about these unknown quantities, ensuring that all users of these data have the same view of the current state of the epidemic.

In this paper we describe a statistical methodology for nowcasting the epidemic statistics, such as hospitalizations or deaths, and the degree of uncertainty, based on the daily reported event frequency and the observed distribution pattern of the reporting delay. The prediction model is building on methods developed in ecology, referred to as the “removal methods” or “capture-retain” models (\cite{Pollock1991_review_papers}).

\section{The current situation of COVID-19 in Sweden}
Each day at 14:00 the Swedish Public Health Agency holds a press conference where new COVID-19 statistics are presented\footnote{The data is then published on https://www.folkhalsomyndigheten.se/smittskydd-beredskap/utbrott/aktuella-utbrott/covid-19/bekraftade-fall-i-sverige/ where we download it every day.}. Deaths is one of the main indicators to follow for understanding the impact of the pandemic on public health in Sweden, but also the number of new admissions to critical care, to hospitals, and the new confirmed cases are reported. One of the reasons for following these indicators is to enable public health professionals and the public to observe the patterns of the evolving, flattened or suppressed epidemic (\cite{Anderson2020_how_will}). In relation to policy, it is of further interest to understand if growth rates change, which could indicate a potential response. However, at the daily presentation only a proportion of the number deaths for each of the most recent days is yet known, and this bias causes an artificial, downward, trend in the data.

The death counts suffer from the longest reporting day. In their daily presentation, the Swedish Public Health Agency warns for this by stopping the 7-day moving average trendline 10 days before the latest date. But not only are deaths often reported far further back than 10 days, a bar plot still shows the latest information from the most recent days creating a sense of a downward trend. In fact, this might be the reason why the number of deaths has been underestimated repeatedly. At the peak, deaths were initially believed to level out at around 60 per day, but after all cases had been reported more than two weeks later, the actual level was closer to 100 (\cite{Ohman2020_antalet_virusdoda}).

\chapter{The removal method}
We propose to use the removal method, developed in animal management (\cite{Pollock1991_review_papers}), to present an estimate of the actual frequencies at a given day and their uncertainty. The method has a long history dating back at least to the 1930s (\cite{Leslie1939_attempt_determine}). However, the first refined mathematical treatment of the method is credited to \cite{Moran1951_mathematical_theory}, more modern derivatives exits today (\cite{Matechou2016_open_models}). It is a commonly applied method today when analyzing age cohorts in fishery and wildlife management.

The removal method that has three major advantages over simply reporting moving averages:
\begin{itemize}
	\item it does not relay previous trend in the data,
	\item we can generate confidence bounds for what is the reasonable range of the uncertainty in the event frequency at a given day,
	\item the uncertainty in the estimate can be carried over to epidemiological models that uses the estimate as input, and hence give more realistic models.
\end{itemize}

A classic example where the method proposed to solve this problem has been used is in estimating statistics of trapping a closed population of animals (\cite{Pollock1991_review_papers}). Each day the trapped animals are collected, and kept, and if there is no immigration the number of trapped animals the following days will, on average, decline. This pattern of declining number of trapped animals allows one to draw inference of the underlying population size. Here we replace the animal population with the true number of deaths or cases in a given day. Instead of traps we have the new reports of COVID-19 events. As the number of new reported deaths for a given day declines, we can draw inference on how many actually died that day. In fact, if we assume that the reporting structure is constant over time we can after a while quickly get good estimate of the actual number.

Suppose for example that on day one, 4 individuals are reported dead for that day. On the second day, 10 deaths are recorded for day two. Then, with no further information, it is reasonable to assume that more people died on day two. If the proportion reported on the first day is 3\%, the actual number of deaths would be 133 for day one and 333 for day two.

If additionally, 60 deaths are reported during the second day to have happened during day one, and on the third day, only 40 are reported for day two, we now have conflicting information. From the first-day reports it seemed like more people had died during day two, but the second day-reports gave the opposite indication. The model we propose systematically deals with such data, and handles many other sources of systematic variation in reporting delay. In fact, the Swedish reporting lag follows a calendar pattern. The number of events reported during weekends is much smaller. To account for this, we  allow the estimated proportions of daily reported cases to follow a probability distribution taking into consideration what type of day it is.

\chapter{Applying the model to COVID-19 in Sweden}
We prorpose a Bayesian version of the removal model that assumes anoverdispersed binomial distribution for the  the daily observations of deaths in Sweden in COVID-19. We then calculate the posterior distribution and prediction median and 95\% uncertainty intervals of the expected deaths from the reported deaths on each specific day. The method and algorithm is thoroughly described in the Supplementary Information.

In Figure 1 we illustrate the similarity and difference between the 7-day moving average and the new Bayesian prediction model with 95\% prediction intervals to the reported number of deaths from COVID-19 in Sweden. The model provides estimates of actual deaths considerably above the reported number of deaths and the uncertainty of the estimate.

% TODO: FIGURE 1 HERE
%Figure 1. The 7-day moving average (blue) and the prediction from the Bayesian model (black) with prediction intervals overlaid. The grey bars represent the number of reported deaths up to May the 12th, 2020, in COVID-19 in Sweden.


%In Figure 2 we use the method to predict the number of new deaths that will be reported in the most recent report and how their date of death will be distributed over time. It is clear from the model prediction that the delay is substantial and therefore interpretations of the daily reported number of deaths without these models to adjust it are difficult.

% TODO: FIGURE 2 here
%Figure 2. The bars represent deaths in COVID-19 in Sweden and the prediction intervals represent the Bayesian predictions of the number of deaths for the specific day in the latest report.

\chapter{Implications and limitations}
The model proposed here has much better ability to estimate the trends in surveillance data with reporting delays, such as the daily COVID-19 reports in Sweden. To generate accurate estimates of the actual event frequencies based on these reports is highly relevant and can have large implications for interpretations of the trends and evolution of disease outbreaks. In Sweden, delays are considerable and exhibit a weekday and holiday pattern that need to be accounted for to draw conclusions from the data. The method and algorithm proposed overcome major shortcomings in the daily interpretation and practice analyzing and controlling the novel Corona virus pandemic. It also provides valuable measures of uncertainty around these estimates, showing readers how large the range of possible outcomes can be.

Whenever case statistics are collected from multiple sources and attributed to its actual event date in the middle of a public health emergency, similar reporting delays to the ones in Sweden will necessarily occur. The method described thus has implications and value beyond Sweden, for any situation where nowcasts of disease event frequencies are of relevance to public health.

Nevertheless, the method also has its limitations. As presented, the model assumes that all deaths are reported in the same manner, given there exists many regions in Sweden this is unlikely to be the case. For example, it is easy to see that the Swedish region Västra Götland follows a different reporting structure compared to Stockholm. Building a model for each region separately would most likely give better results and make the assumptions more reasonable. Unfortunately we do not currently have access to the high resolution data required to do so. Another limitation is that the model assumes that the number of new reported deaths for a given day cannot be negative, which is not actually true, due to miscount or misclassification of days. The number of such cases is very small, however, and its removal should not make much difference. The central assumption of the model is that the proportions deaths reported each day is fixed (up to the known covariates). If actual reporting standards change over time and its not explicitly modelled by a covariate, the model will not be able to account for this. But reporting likely becomes faster as the crisis infrastructure improves. One can imagine that after a while the reporting improves, or is changed, if this is not accounted for by a covariate in the model, it will report incorrect numbers. Of course, there might be unknown variables that we have failed to incorporate, but at the least the model is an improvement from the estimates using moving averages.

\chapter{Conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
\printbibliography%
\backmatter%
\appendix%
\chapter{Appendix}
\input{appendix.tex}%

\end{document}

\documentclass[a4paper,11pth]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[square,numbers]{natbib}
%\usepackage[style=nature]{biblatex}
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{booktabs}
\usepackage{graphicx}
\DeclareGraphicsExtensions{.pdf,.png,.jpg,.eps}
\usepackage{array}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{hyperref}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}
\newcommand{\mv}[1]{{\boldsymbol{#1}}}

% TITLE

\title{Nowcasting Covid-19 statistics reported with delay: a case-study of Sweden}
\date{\today}
\author{
.
}

\begin{document}
    \maketitle
    \begin{abstract}
        The new coronavirus disease --- COVID-2019 --- is rapidly spreading through the world. The availability of unbiased timely surveillance statistics, such as the trends in disease frequencies, are a key to evaluating and planning responses. But due to reporting delays, the most recently reported numbers are often underestimating of the total number of new infections, hospitalizations and deaths. This sometimes creates an illusion of a downward trend. Here we describe a statistical methodology for predicting the expected actual daily surveillance frequencies and their uncertainty, considering historical reporting delays. The methodology takes into account the observed distribution pattern of the lag. It is derived from the ``removal method'', a well-established estimation framework in the field of ecology.
	\end{abstract}
%%%%%%%%%%%%%%%%%%%
% MAIN TEXT SECTION
\section{Pandemic response demands timely data}
The SARS-CoV-2 pandemic is affecting societies all around the world. As countries are challenged to control and fight back, they are in need of timely, unbiased, surveillance data for monitoring trends and making fast and well-informed decisions \citep{No_author_2020_coronavirus_three}. Official statistics are usually reported with long delay after thorough verification, but in the midst of a deadly pandemic, real time data is of critical importance for policymakers to evaluate and plan rapid responses \citep{Jajosky2004_evaluation_reporting}. But as a general rule, the latest data are often not complete, but change as new information is reported. In fact, reporting delays make the most recent days have the least cases accounted for, producing a dangerous illusion of an always improving outlook.

Still, these unfinished surveillance statistics offer crucial information. If the pandemic is indeed slowing, we should not wait for the data to be finalized before using it. Rather, we argue that actual case counts and deaths should be nowcasted to account for reporting delays, thus allowing policymakers to use the latest numbers available surveillance without being misled by the obvious reporting bias.

Such predictions provide an additional feature that is perhaps even more important. They explicitly model the uncertainty in these unknown quantities, ensuring that all users of these data have the same view of the current state of the epidemic, including the uncertainty.

In this paper we describe a statistical methodology for nowcasting the surveillance statistics, such as hospitalizations or deaths, and their degrees of uncertainty, based on the daily reported event frequency and the observed distribution pattern of reporting delays. The prediction model is building on methods developed in ecology, referred to as the ``removal method'' \citep{Pollock1991_review_papers}.

To help motivate why such forecasting is needed, we now turn to the case of Sweden, and illustrate how this method and can provide more reliable and relevant data to decision-makers in the midst of a pandemic. We stress, however, that the model is flexible by design and that it could easily be applied to other countries and surveillance data as well.

\subsection{The current situation of COVID-19 in Sweden}
The Swedish Public Health Agency updates the COVID-19 statistics daily (the data is published on https://www.folkhalsomyndigheten.se/smittskydd-beredskap
/utbrott/aktuella-utbrott/covid-19/bekraftade-fall-i-sverige/).. During frequently re-occurring press conference, they present updates on the number of deaths, admissions to hospitals and intensive care, as well as case counts.

One of the reasons for following these indicators is to enable public health professionals and the public to observe the evolving patterns of the epidemic \citep{Anderson2020_how_will}. In relation to policy, it is of specific interest to understand if the growth rates changes, which could indicate the need for a policy response. However, in each daily report only a proportion of the number of recent deaths is yet known, and this bias produces makes the recent data presented less useful.

The death counts strongly suffer from the longer reporting delays. In their daily press conference, the Swedish Public Health Agency warns for this by stopping the reported 7-day moving average trend line 10 days before the latest date. But not only are deaths often reported far further back than 10 days, a bar plot still shows the latest information, creating a false impression of sense of a downward trend. In fact, in the Swedish situation, this might be the reason why the number of daily deaths have been underestimated repeatedly. As an example illustrating this, at the peak of the Swedish outbreak in the spring 2020, deaths were initially believed to level out at around 60 per day, but after all cases had been reported more than two weeks later, the actual number was close to 120 \citep{Ohman2020_antalet_virusdoda}.

\section{The removal method}
To correct for the reporting delays we propose to use the removal method, developed in animal management \citep{Pollock1991_review_papers}, to present an estimate of the actual frequencies at a given day and their uncertainty. The method has a long history dating back at least to the 1930s \citep{Leslie1939_attempt_determine}. However, the first refined mathematical treatment of the method is credited to \cite{Moran1951_mathematical_theory}, more modern derivatives exits today \citep{Matechou2016_open_models}. It is a commonly applied method today when analyzing age cohorts in fishery and wildlife management.

The removal method has three major advantages over the simplistic approach to just reporting moving averages:

\begin{itemize}
	\item it does not relay any previous trend in the data,
	\item we can generate prediction intervals for the uncertainty about daily true frequencies,
	\item the uncertainty estimates can be carried over to epidemiological models to help create more realistic models.
\end{itemize}

A classic example where the method proposed to solve this problem has been used is in estimating statistics of trapping a closed population of animals \citep{Pollock1991_review_papers}. Each day the trapped animals are collected, and kept, and if there is no immigration the number of trapped animals the following days will, on average, decline. This pattern of declining number of trapped animals allows one to draw inference of the underlying population size. Here we replace the animal population with the true number of deaths on a given day. For COVID-19, instead of traps we have the new reports of COVID--19 events. As the number of non-yet reported deaths for a given day declines according to some patterns over time, we can use this patterns to draw inference on how many actually died a specific day. If we assume that the reporting structure is constant over time we can after a while quickly get good estimate of the actual number, not the reported one.

Suppose for example that on day one, 4 individuals are reported dead for that day. On the second day, 10 deaths are recorded for day two. Then, with no further information, it is reasonable to assume that more people died on day two. If the proportion reported on the first day is 3\%, the actual number of deaths would be 133 for day one and 333 for day two.

If additionally, 60 deaths are reported during the second day to have happened during day one, and on the third day, only 40 are reported for day two, we now have conflicting information. From the first-day reports it seemed like more people had died during day two, but the second day-reports gave the opposite indication. The model we propose systematically deals with such data, and handles many other sources of systematic variation in reporting delay. In fact, the Swedish reporting lag follows a calendar pattern. The number of events reported during weekends is much smaller. To account for this, we allow the estimated proportions of daily reported cases to follow a probability distribution taking into consideration what type of day it is.

We note that a similar method has been proposed for delay adjusted reporting, but without using the removal method \citep{lawless1994adjustments}. In \cite{lawless1994adjustments} the author developed the Occurred But Not Reported method (OBNR), which can give a frequentist point estimate of the number of deaths, and under a Poisson distributional assumption, generate prediction intervals. A Bayesian version of this method for nowcasting was developed in \cite{hohle2014bayesian}.

\section{Applying the model to COVID-19 in Sweden}
We propose a Bayesian version of the removal model that assumes an overdispersed binomial distribution for the daily observations of deaths in Sweden in COVID-19. We then calculate the posterior distribution, prediction median and 95\% prediction intervals of the expected deaths from the reported deaths on each specific day. The method and algorithm is thoroughly described in the Supplementary Information.

To get accurate estimates we apply two institution-specific corrections. First, we only count workdays as constituting reporting delay, as very few deaths are reported during weekends. Second, we apply a constant bias correction to account for the fact that Swedish deaths come from two distinct populations with different trends: deaths in hospitals, and in elderly care.

In Figure~\ref{fig:latest_prediction} we apply the model to the latest statistics from Sweden. The graph shows reported and predicted deaths (with uncertainty intervals) as bars, and a dashed line plots the 7-day (centered) moving average. A version without predictions is used in the Public Health Agency\'s daily press briefings. As expected, the model provides estimates of actual deaths considerably above the reported number of deaths. We note specifically how the model predicts additional deaths above the moving average line.

\subsection{Model Performance}
To judge whether or not the model is accurate we need to compare it to a benchmark. The moving average of reported deaths is not useful, since it is biased for deaths that occurred within the last week. Instead, we create a benchmark prediction by using a Normal distribution where the mean and standard deviation is taken from the historical lags from the last two weeks to the reported numbers\footnote{For a death date two days ago we add the mean of deaths reported after 3 days, 4 days, etc. We use the sum of standard deviations to generate the prediction intervals, assuming that lags are independent across days. The exact calculation is described in the appendix.}. 

Figure~\ref{fig:four_dates} depicts four randomly chosen dates where the model is compared to the benchmark. The model and the benchmark are tasked with predicting the total number of individuals who have died at a given date and have been reported within 14 days of that date. As time progresses, more deaths are reported and the dashed grey line approaches the horizontal line. Meanwhile model uncertainty decreases.

Figure~\ref{fig:model_metrics} shows model performance compared to the benchmark for three difference performance metrics. All three graphs are based on predictions of reported deaths within 14 days, and show how performance increases as more data has been reported. Each data point is the average of all dates where predictions can be evaluated.
In forecast evaluation, a function that guarantees, asymptotically, that the forecasting distribution (if available) will be chosen, is known as a proper scoring rule, see \cite{gneiting2007strictly}.
In \cite{hohle2014bayesian} validation was done using the proper scoring rules logarithmic score and ranked probability score. These two scores requires access to either the PMF or CDF of the predictive distribution. Since we don't have easy access to these functions we instead use the  SCRPS (Scaled continuous proability ranking score, see definition in Appendix) \citep{bolin2019scale}. The central plot shows the width of the prediction intervals, and the rightmost one the proportion of PI\'s that cover the true value.

Benchmark and model point estimates are similarly close to the truth. The model produces tighter prediction intervals. For 8-5 days of reporting lag (see Figure \ref{fig:model_metrics}), the intervals are too tight. This is likely because the Public Health Agency queries the Swedish death registry for Covid-19 deaths only once or twice a week. Since we do not know the process, it has not been explicitly modeled.

\section{Implications and limitations}
The model proposed here can estimate the trends in surveillance data with reporting delays, such as the daily COVID-19 reports in Sweden. To generate accurate estimates of the actual event frequencies based on these reports is highly relevant and can have large implications for interpretations of the trends and evolution of disease outbreaks. In Sweden, delays are considerable and exhibit a weekday and holiday pattern that need to be accounted for to draw conclusions from the data. The method and algorithm proposed overcomes major shortcomings in the daily interpretation and practice analyzing and controlling the SARS-CoV-2 virus pandemic. It also provides valuable measures of uncertainty around these estimates, showing users how large the range of possible outcomes can be.

Whenever case statistics are collected from multiple sources and attributed to its actual event date in the middle of a public health emergency, similar reporting delays to the ones in Sweden will necessarily occur. The method described thus has implications and value beyond Sweden, for any situation where nowcasts of surveillance data are of relevance to public health.

In \cite{schneble2020nowcasting} nowcasting of number of Covid-19 deaths in Germany was preformed. For nowcasting they applied the OBNR method, using penalized smoothing splines. The accuracy of their nowcasting model is, however, not possible to compare to our model as the study by Schneble et al. didn\'t validate the nowcasting on data withheld from the model fitting. 

Our method has its limitations. As presented, the model assumes that all deaths are reported in the same manner. Given there exists many regions in Sweden this is unlikely to be the case. For example, it is easy to see that the Swedish region Västra Götland follows a different reporting structure than Stockholm. Building a model for each region separately would most likely give better results and make the assumptions more reasonable. Unfortunately we do not currently have access to the high resolution data required to do so. 

Moreover, deaths seem to be reported from two distinct populations that follow different trends. At the time of writing, the daily deaths in elderly care, reported with a longer delay, seem to be decreasing slower than hospital deaths. But statistics offer only aggregate numbers, prohibiting us from modeling two distinct processes. However, we have noted a clear decline in proportions of deaths reported the two first working days. For example, out of all deaths that occurred on the second of April, $\approx 30\%$ were reported within the first two workdays, whereas for the eighteenth of May only $\approx 10\%$ were reported that fast. We address this by assuming that the deaths reported during the two first working days comes from a different population than the remainder of days.

Another limitation is that the model assumes that the number of new reported deaths for a given day cannot be negative, which is not actually true, due to miscount or misclassification of days. The number of such cases is very small, however, and its removal should not make much difference. The central assumption of the model is that the proportions deaths reported each day is fixed (up to the known covariates). If actual reporting standards change over time, the model will not be able to account for this. But reporting likely becomes faster as the crisis infrastructure improves. One can imagine that after a while the reporting improves, or is changed, if this is not accounted for by a covariate in the model, it will report incorrect numbers. Of course, there might be unknown variables that we have failed to incorporate, but at the least the model is an improvement from the estimates using moving averages. When the covariates to the reporting delay pattern are known, the model can incorporate them and provide more accurate predictions. 

\section{Conclusion}
In this paper, we provide a method to accurately adjust for reporting delays. This is illustrated by nowcasting daily Covid-19 deaths in Sweden, which are reported with strong delay patterns. By systematically accounting for the delay by nowcasting, better timing in the evaluation and planning of responses and policy can be achieved, which is of great importance for in pandemic situations. Our model also gives precise uncertainty intervals, making sure users of these statistics are aware of the fast-paced changes that are possible during pandemics.

\section{Additional Information}
The authors declare no conflict of interest.
%%%%%%%%%%%%%%%%%%%%%%%%%%%'

%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

% Author contributions
\bibliographystyle{unsrt}
\bibliography{bibliography}
\input{contributions.tex}%

\newpage
\section{Figure legends}
Figure 1. Swedish Covid-19 deaths as of 2020-06-04 and model predictions.

Figure 2. Model accuracy over time for four dates, compared to a benchmark.

Figure 3. Model accuracy over time for four dates, compared to benchmark.


\newpage

\input{Figure1.tex}%
\newpage
\input{Figure2.tex}%
\newpage

\input{Figure3.tex}%


\newpage
\appendix
\section{Appendix}
\input{appendix.tex}%

\end{document}
